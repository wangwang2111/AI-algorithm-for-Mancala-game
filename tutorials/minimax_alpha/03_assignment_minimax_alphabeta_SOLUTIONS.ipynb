{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc356096",
   "metadata": {},
   "source": [
    "# Assignment: Minimax, Alpha–Beta, Ordering, Simulation, Custom Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09796897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engine imports\n",
    "import os, sys, pathlib, copy, math, time, random\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "REPO_ROOT = pathlib.Path().resolve().parents[1]  # .../tutorials/minimax_alpha/ -> repo root\n",
    "SRC = REPO_ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "from mancala_ai.engine.core import new_game, legal_actions, step, evaluate\n",
    "\n",
    "def score_for(state: Dict, root_idx: int) -> float:\n",
    "    s = copy.deepcopy(state); s[\"current_player\"] = root_idx\n",
    "    return float(evaluate(s))\n",
    "\n",
    "def print_state(s):\n",
    "    p0, p1 = s[\"pits\"][0], s[\"pits\"][1]\n",
    "    st0, st1 = s[\"stores\"]\n",
    "    turn = s[\"current_player\"]\n",
    "    # Top row is player 1 (reverse display for board-like view)\n",
    "    print(\"+----- Mancala -----+\")\n",
    "    print(\"P1 store:\", st1)\n",
    "    print(\"P1 pits: \", list(reversed(p1)))\n",
    "    print(\"P0 pits: \", p0)\n",
    "    print(\"P0 store:\", st0)\n",
    "    print(\"Turn: P\", turn, sep=\"\")\n",
    "    print(\"+-------------------+\")\n",
    "    \n",
    "class Stats:\n",
    "    def __init__(self): self.visits = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ed3ba",
   "metadata": {},
   "source": [
    "## Minimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1d358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(state: Dict, depth: int, root_idx: int, stats: Stats):\n",
    "    stats.visits += 1\n",
    "    if depth == 0 or sum(state[\"pits\"][0]) == 0 or sum(state[\"pits\"][1]) == 0:\n",
    "        return score_for(state, root_idx), None\n",
    "    acts = legal_actions(state)\n",
    "    if not acts: return score_for(state, root_idx), None\n",
    "    is_max = (state[\"current_player\"] == root_idx)\n",
    "    best_move = acts[0]\n",
    "    if is_max:\n",
    "        best = -math.inf\n",
    "        for a in acts:\n",
    "            ns, _, _ = step(state, a)\n",
    "            reduce = 0 if ns[\"current_player\"] == state[\"current_player\"] else 1\n",
    "            v, _ = minimax(ns, depth - reduce, root_idx, stats)\n",
    "            if v > best: best, best_move = v, a\n",
    "        return best, best_move\n",
    "    else:\n",
    "        best = math.inf\n",
    "        for a in acts:\n",
    "            ns, _, _ = step(state, a)\n",
    "            reduce = 0 if ns[\"current_player\"] == state[\"current_player\"] else 1\n",
    "            v, _ = minimax(ns, depth - reduce, root_idx, stats)\n",
    "            if v < best: best, best_move = v, a\n",
    "        return best, best_move\n",
    "\n",
    "def choose_move_minimax(state: Dict, depth: int = 5):\n",
    "    st = Stats()\n",
    "    _, mv = minimax(state, depth, state[\"current_player\"], st)\n",
    "    if mv is None:\n",
    "        acts = legal_actions(state); mv = int(acts[0]) if acts else 0\n",
    "    return int(mv), st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f89df6",
   "metadata": {},
   "source": [
    "## Alpha–Beta (reference, with optional ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381401f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta(state: Dict, depth: int, alpha: float, beta: float, root_idx: int,\n",
    "              stats: Stats, ordering_fn: Optional[Callable[[Dict, int, List[int]], List[int]]] = None):\n",
    "    stats.visits += 1\n",
    "    if depth == 0 or sum(state[\"pits\"][0]) == 0 or sum(state[\"pits\"][1]) == 0:\n",
    "        return score_for(state, root_idx), None\n",
    "    acts = legal_actions(state)\n",
    "    if not acts: return score_for(state, root_idx), None\n",
    "    ordered = ordering_fn(state, root_idx, acts) if ordering_fn else acts\n",
    "    is_max = (state[\"current_player\"] == root_idx)\n",
    "    best_move = ordered[0]\n",
    "    if is_max:\n",
    "        val = -math.inf; a = alpha\n",
    "        for mv in ordered:\n",
    "            ns, _, _ = step(state, mv)\n",
    "            reduce = 0 if ns[\"current_player\"] == state[\"current_player\"] else 1\n",
    "            child_v, _ = alphabeta(ns, depth - reduce, a, beta, root_idx, stats, ordering_fn)\n",
    "            if child_v > val: val, best_move = child_v, mv\n",
    "            a = max(a, val)\n",
    "            if beta <= a: break\n",
    "        return val, best_move\n",
    "    else:\n",
    "        val = math.inf; b = beta\n",
    "        for mv in ordered:\n",
    "            ns, _, _ = step(state, mv)\n",
    "            reduce = 0 if ns[\"current_player\"] == state[\"current_player\"] else 1\n",
    "            child_v, _ = alphabeta(ns, depth - reduce, alpha, b, root_idx, stats, ordering_fn)\n",
    "            if child_v < val: val, best_move = child_v, mv\n",
    "            b = min(b, val)\n",
    "            if b <= alpha: break\n",
    "        return val, best_move\n",
    "\n",
    "def choose_move_alphabeta(state: Dict, depth: int = 7, ordering_fn=None):\n",
    "    st = Stats()\n",
    "    _, mv = alphabeta(state, depth, -1e9, 1e9, state[\"current_player\"], st, ordering_fn)\n",
    "    if mv is None:\n",
    "        acts = legal_actions(state); mv = int(acts[0]) if acts else 0\n",
    "    return int(mv), st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b609c",
   "metadata": {},
   "source": [
    "## Part A — Implement simple move ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95f5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_moves_by_one_ply_score(state: Dict, root_idx: int, acts: List[int]) -> List[int]:\n",
    "    scored = []\n",
    "    for a in acts:\n",
    "        ns, _, _ = step(state, a)\n",
    "        scored.append((score_for(ns, root_idx), a))\n",
    "    scored.sort(reverse=True)\n",
    "    return [a for _, a in scored]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a6722f",
   "metadata": {},
   "source": [
    "## Part B — Compare visits with vs without ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4574bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----- Mancala -----+\n",
      "P1 store: 10\n",
      "P1 pits:  [5, 2, 0, 6, 0, 4]\n",
      "P0 pits:  [0, 2, 0, 5, 2, 7]\n",
      "P0 store: 5\n",
      "Turn: P0\n",
      "+-------------------+\n",
      "Alpha–Beta d=7 WITHOUT ordering: move=4, nodes=29389\n",
      "Alpha–Beta d=7 WITH    ordering: move=4, nodes=22161\n"
     ]
    }
   ],
   "source": [
    "CHALLENGE_STATE = {\n",
    "    \"pits\":   [[0, 2, 0, 5, 2, 7], [4, 0, 6, 0, 2, 5]],\n",
    "    \"stores\": [5, 10],\n",
    "    \"current_player\": 0,\n",
    "}\n",
    "print_state(CHALLENGE_STATE)\n",
    "\n",
    "def compare_visits_on_state(state: Dict, depth: int = 7):\n",
    "    s1 = copy.deepcopy(state); s2 = copy.deepcopy(state)\n",
    "    mv_no, st_no   = choose_move_alphabeta(s1, depth=depth, ordering_fn=None)\n",
    "    mv_ord, st_ord = choose_move_alphabeta(s2, depth=depth, ordering_fn=order_moves_by_one_ply_score)\n",
    "    print(f\"Alpha–Beta d={depth} WITHOUT ordering: move={mv_no}, nodes={st_no.visits}\")\n",
    "    print(f\"Alpha–Beta d={depth} WITH    ordering: move={mv_ord}, nodes={st_ord.visits}\")\n",
    "\n",
    "compare_visits_on_state(CHALLENGE_STATE, depth=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8276d",
   "metadata": {},
   "source": [
    "## Part C — 100-game simulations & metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39787379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_agent():\n",
    "    def _fn(state: Dict):\n",
    "        acts = legal_actions(state); mv = random.choice(acts) if acts else 0\n",
    "        st = Stats(); return mv, st\n",
    "    return _fn\n",
    "\n",
    "def minimax_agent(depth: int):\n",
    "    def _fn(state: Dict):\n",
    "        return choose_move_minimax(state, depth=depth)\n",
    "    return _fn\n",
    "\n",
    "def alphabeta_agent(depth: int, ordering: bool = False):\n",
    "    def _fn(state: Dict):\n",
    "        order = order_moves_by_one_ply_score if ordering else None\n",
    "        return choose_move_alphabeta(state, depth=depth, ordering_fn=order)\n",
    "    return _fn\n",
    "\n",
    "def play_game(agent0, agent1, max_plies=500):\n",
    "    s = new_game(); moves = 0\n",
    "    times_0, times_1, nodes_0, nodes_1 = [], [], [], []\n",
    "    while sum(s[\"pits\"][0]) > 0 and sum(s[\"pits\"][1]) > 0 and moves < max_plies:\n",
    "        turn = s[\"current_player\"]\n",
    "        agent = agent0 if turn == 0 else agent1\n",
    "        t0 = time.perf_counter()\n",
    "        mv, st = agent(copy.deepcopy(s))\n",
    "        dt = time.perf_counter() - t0\n",
    "        s, _, _ = step(s, mv)\n",
    "        moves += 1\n",
    "        if turn == 0:\n",
    "            times_0.append(dt); nodes_0.append(st.visits)\n",
    "        else:\n",
    "            times_1.append(dt); nodes_1.append(st.visits)\n",
    "    st0, st1 = s[\"stores\"]\n",
    "    winner = 0 if st0 > st1 else 1 if st1 > st0 else -1\n",
    "    return {\"winner\": winner, \"moves\": moves,\n",
    "            \"times_0\": times_0, \"times_1\": times_1,\n",
    "            \"nodes_0\": nodes_0, \"nodes_1\": nodes_1}\n",
    "\n",
    "def run_series(agentA, agentB, n_games=100, seed=42):\n",
    "    random.seed(seed)\n",
    "    wins_A = wins_B = draws = 0\n",
    "    moves_list = []; tA=[]; tB=[]; nA=[]; nB=[]\n",
    "    for g in range(n_games):\n",
    "        if g % 2 == 0:\n",
    "            res = play_game(agentA, agentB)\n",
    "            if   res[\"winner\"] == 0: wins_A += 1\n",
    "            elif res[\"winner\"] == 1: wins_B += 1\n",
    "            else: draws += 1\n",
    "            tA += res[\"times_0\"]; tB += res[\"times_1\"]\n",
    "            nA += res[\"nodes_0\"]; nB += res[\"nodes_1\"]\n",
    "        else:\n",
    "            res = play_game(agentB, agentA)\n",
    "            if   res[\"winner\"] == 0: wins_B += 1\n",
    "            elif res[\"winner\"] == 1: wins_A += 1\n",
    "            else: draws += 1\n",
    "            tA += res[\"times_1\"]; tB += res[\"times_0\"]\n",
    "            nA += res[\"nodes_1\"]; nB += res[\"nodes_0\"]\n",
    "        moves_list.append(res[\"moves\"])\n",
    "    def _avg(xs): return (sum(xs)/len(xs)) if xs else 0.0\n",
    "    return {\n",
    "        \"games\": n_games,\n",
    "        \"wins_A\": wins_A, \"wins_B\": wins_B, \"draws\": draws,\n",
    "        \"win_rate_A\": wins_A/n_games, \"win_rate_B\": wins_B/n_games,\n",
    "        \"avg_moves_per_game\": _avg(moves_list),\n",
    "        \"avg_time_per_move_A\": _avg(tA), \"avg_time_per_move_B\": _avg(tB),\n",
    "        \"avg_nodes_per_move_A\": _avg(nA), \"avg_nodes_per_move_B\": _avg(nB),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f47119",
   "metadata": {},
   "source": [
    "### 6.1) Run: Minimax vs Alpha-Beta (after you implement Minimax) and comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fe73f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'games': 100,\n",
       " 'wins_A': 53,\n",
       " 'wins_B': 41,\n",
       " 'draws': 6,\n",
       " 'win_rate_A': 0.53,\n",
       " 'win_rate_B': 0.41,\n",
       " 'avg_moves_per_game': 41.47,\n",
       " 'avg_time_per_move_A': 7.82604387516726e-06,\n",
       " 'avg_time_per_move_B': 8.660614305950896e-06,\n",
       " 'avg_nodes_per_move_A': 0.0,\n",
       " 'avg_nodes_per_move_B': 0.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = run_series(random_agent(), random_agent(), n_games=100, seed=123)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d07bcb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha–Beta (no ordering) vs Random\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'games': 10,\n",
       " 'wins_A': 5,\n",
       " 'wins_B': 5,\n",
       " 'draws': 0,\n",
       " 'win_rate_A': 0.5,\n",
       " 'win_rate_B': 0.5,\n",
       " 'avg_moves_per_game': 57.0,\n",
       " 'avg_time_per_move_A': 0.09040524237916862,\n",
       " 'avg_time_per_move_B': 0.8655028674280753,\n",
       " 'avg_nodes_per_move_A': 5635.350877192983,\n",
       " 'avg_nodes_per_move_B': 52738.36842105263}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Alpha–Beta (no ordering) vs Random\")\n",
    "summary = run_series(alphabeta_agent(depth=5, ordering=False), minimax_agent(depth=5), n_games=10, seed=123)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b5aafb",
   "metadata": {},
   "source": [
    "## Part D — Your own heuristic Minimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_score_for(state: Dict, root_idx: int) -> float:\n",
    "    # TODO: replace with your own heuristic formula\n",
    "    return score_for(state, root_idx)\n",
    "\n",
    "def minimax_with_heuristic(state: Dict, depth: int, root_idx: int, stats: Stats):\n",
    "    stats.visits += 1\n",
    "    if depth == 0 or sum(state[\"pits\"][0]) == 0 or sum(state[\"pits\"][1]) == 0:\n",
    "        return heuristic_score_for(state, root_idx), None\n",
    "    acts = legal_actions(state)\n",
    "    if not acts: return heuristic_score_for(state, root_idx), None\n",
    "    is_max = (state[\"current_player\"] == root_idx)\n",
    "    best_move = acts[0]\n",
    "    if is_max:\n",
    "        best = -math.inf\n",
    "        for a in acts:\n",
    "            ns, _, _ = step(state, a)\n",
    "            reduce = 0 if ns[\"current_player\"] == state[\"current_player\"] else 1\n",
    "            v, _ = minimax_with_heuristic(ns, depth - reduce, root_idx, stats)\n",
    "            if v > best: best, best_move = v, a\n",
    "        return best, best_move\n",
    "    else:\n",
    "        best = math.inf\n",
    "        for a in acts:\n",
    "            ns, _, _ = step(state, a)\n",
    "            reduce = 0 if ns[\"current_player\"] == state[\"current_player\"] else 1\n",
    "            v, _ = minimax_with_heuristic(ns, depth - reduce, root_idx, stats)\n",
    "            if v < best: best, best_move = v, a\n",
    "        return best, best_move\n",
    "\n",
    "def choose_move_minimax_heuristic(state: Dict, depth: int = 5):\n",
    "    st = Stats()\n",
    "    _, mv = minimax_with_heuristic(state, depth, state[\"current_player\"], st)\n",
    "    if mv is None:\n",
    "        acts = legal_actions(state); mv = int(acts[0]) if acts else 0\n",
    "    return int(mv), st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Heuristic Minimax vs Random\")\n",
    "def heur_agent(depth=5):\n",
    "    def _fn(state):\n",
    "        return choose_move_minimax_heuristic(state, depth=depth)\n",
    "    return _fn\n",
    "\n",
    "summary = run_series(heur_agent(depth=5), random_agent(), n_games=100, seed=123)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
